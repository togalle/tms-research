{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne-icalabel in d:\\coding\\tms-research\\.conda\\lib\\site-packages (0.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: mne>=1.2 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.21 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (1.26.4)\n",
      "Requirement already satisfied: packaging in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (24.0)\n",
      "Requirement already satisfied: pooch in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (1.8.1)\n",
      "Requirement already satisfied: psutil in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (5.9.8)\n",
      "Requirement already satisfied: scipy>=1.4.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne-icalabel) (1.12.0)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne>=1.2->mne-icalabel) (3.8.3)\n",
      "Requirement already satisfied: tqdm in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne>=1.2->mne-icalabel) (4.66.2)\n",
      "Requirement already satisfied: decorator in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne>=1.2->mne-icalabel) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne>=1.2->mne-icalabel) (3.1.3)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from mne>=1.2->mne-icalabel) (0.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from pooch->mne-icalabel) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from pooch->mne-icalabel) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (2.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch->mne-icalabel) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch->mne-icalabel) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch->mne-icalabel) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch->mne-icalabel) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from jinja2->mne>=1.2->mne-icalabel) (2.1.5)\n",
      "Requirement already satisfied: colorama in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from tqdm->mne>=1.2->mne-icalabel) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\coding\\tms-research\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne>=1.2->mne-icalabel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install mne-icalabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import utils\n",
    "\n",
    "# Specify graph rendering method\n",
    "# %matplotlib widget\n",
    "plt.switch_backend(\"TkAgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ./dataset\\TMS-EEG-H_02_S1b_spTEP_pre.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 2696199  =      0.000 ...   539.240 secs...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Extracting parameters from ./dataset\\TMS-EEG-H_02_S1b_rsEEG_pre.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 3984899  =      0.000 ...   796.980 secs...\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"./dataset\"\n",
    "FILENAME_TEMPLATE = \"TMS-EEG-H_02_S1b_{}_{}.vhdr\"\n",
    "\n",
    "spTEP_pre_raw = mne.io.read_raw_brainvision(\n",
    "    os.path.join(DATASET_PATH, FILENAME_TEMPLATE.format(\"spTEP\", \"pre\")), preload=True\n",
    ")\n",
    "sampling_rate = spTEP_pre_raw.info[\"sfreq\"]\n",
    "events, event_dict = mne.events_from_annotations(spTEP_pre_raw)\n",
    "tms_indices = [event[0] for event in events if event[2] == 1]\n",
    "\n",
    "rsEEG_pre_raw = mne.io.read_raw_brainvision(\n",
    "    os.path.join(DATASET_PATH, FILENAME_TEMPLATE.format(\"rsEEG\", \"pre\")), preload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utilities\n",
    "def plot_single_response(eeg_data, channel=\"Pz\", tmin=-0.005, tmax=0.01):\n",
    "    events, event_dict = mne.events_from_annotations(eeg_data)\n",
    "    event_id = event_dict[\"Stimulus/S  1\"]\n",
    "    epochs = mne.Epochs(\n",
    "        eeg_data,\n",
    "        events,\n",
    "        event_id=event_id,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "        picks=channel,\n",
    "    )\n",
    "\n",
    "    epochs.plot(picks=channel, n_epochs=1, show=True, scalings={\"eeg\": 50e-4})\n",
    "\n",
    "\n",
    "def plot_average_epoch(epochs, start=-0.05, end=0.25):\n",
    "    data = epochs.get_data()\n",
    "    mean_responses = np.mean(data, axis=0)\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    for i, mean_response in enumerate(mean_responses):\n",
    "        selected_data = mean_response[selected_indices]\n",
    "        selected_time_points = time_points[selected_indices]\n",
    "        plt.plot(selected_time_points, selected_data, label=f\"Channel {i+1}\")\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_response(eeg):\n",
    "    utils.plot_average_response(eeg, tmin=-0.05, tmax=0.25)  # Check full response\n",
    "    utils.plot_single_response(\n",
    "        eeg, channel=\"Pz\", tmin=-0.05, tmax=0.05\n",
    "    )  # Check for TMS pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning - spTEP\n",
    "\n",
    "The paper of Bertazzoli et al. (2021) compares 4 pipelines: ARTIST, TMSEEG, TESA and SOUND-SSP-SIR, all of which work decently well in varying degrees. There are common steps, but TESA will be the one that will be most closely followed. The current steps are as follows:\n",
    "\n",
    "1. Remove EOG\n",
    "2. Remove TMS pulse\n",
    "3. Downsample\n",
    "4. **ICA - 1**\n",
    "5. Bandpass - Notch filters\n",
    "6. **ICA - 2**\n",
    "7. Rereference\n",
    "\n",
    "Currently, there is no demeaning or bad channel rejection present as in TESA. Demeaning is done before the TMS-pulse interpolation, and baseline correction should be done as last step after rereferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1251 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 150 events and 501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using matplotlib as 2D backend.\n"
     ]
    }
   ],
   "source": [
    "plot_response(spTEP_pre_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/raw-average.png)\n",
    "![](img/single-pulse-raw.JPG)\n",
    "\n",
    "The figure above already shows 2 major artifacts that cleaning will have the biggest impact on: TMS-pulse interpolation and demeaning/baseline correction. The major TMS-pulse artifact falls closely within the range of 2ms before until 5ms after the pulse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spTEP_copy = spTEP_pre_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOG removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_EOG(eeg_data):\n",
    "    eeg_data.drop_channels([\"HEOG\", \"VEOG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_EOG(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMS pulse removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_range_indices(tms_index, start, end, sampling_rate):\n",
    "    \"\"\"\n",
    "    start and end are positive in seconds\n",
    "    sampling rate in Hz\n",
    "    \"\"\"\n",
    "    samples_before = int(start * sampling_rate)\n",
    "    samples_after = int(end * sampling_rate)\n",
    "\n",
    "    start_index = max(0, tms_index - samples_before)\n",
    "    end_index = tms_index + samples_after\n",
    "\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_TMS_pulse(eeg_data_raw, tms_indices, start, end, sampling_rate):\n",
    "    eeg_data = eeg_data_raw.get_data()\n",
    "    num_electrodes = eeg_data.shape[0]\n",
    "    for tms_index in tms_indices:\n",
    "        start_index, end_index = calculate_range_indices(\n",
    "            tms_index, start, end, sampling_rate\n",
    "        )\n",
    "        for i in range(num_electrodes):\n",
    "            x = [start_index - 2, start_index - 1, end_index + 1, end_index + 2]\n",
    "            y = [\n",
    "                eeg_data[i, start_index - 2],\n",
    "                eeg_data[i, start_index - 1],\n",
    "                eeg_data[i, end_index + 1],\n",
    "                eeg_data[i, end_index + 2],\n",
    "            ]\n",
    "            x_new = np.arange(start_index, end_index + 1)\n",
    "\n",
    "            interp_func = interp1d(x, y, kind=\"cubic\")\n",
    "            eeg_data[i, start_index : end_index + 1] = interp_func(x_new)\n",
    "\n",
    "    eeg_data_raw._data = eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_TMS_pulse(\n",
    "    spTEP_copy, tms_indices, 0.005, 0.01, sampling_rate\n",
    ")  # 2ms before, 5ms after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1501 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 150 events and 501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolated-average.png)\n",
    "![](img/single-pulse-interpolated.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This succesfully removed the TMS pulse artifact by using cubic interpolation based on the 2 values before and 2 values after the range that is to be interpolated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "The original data was captured with a sampling frequency of 5000 Hz. 1000 Hz is chosen as the frequency to be downsampled to, as this means that, following Nyquists theorem, the highest frequency that will be accurately recorded is 500 Hz, which should be more than enough for further analysis, as the gamma band is often referred to as 30-100 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(eeg_data, sample_rate=1000):\n",
    "    eeg_data.resample(sample_rate, npad=\"auto\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:   20.8s finished\n"
     ]
    }
   ],
   "source": [
    "downsample(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 301 original time points ...\n",
      "1 bad epochs dropped\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 150 events and 101 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/single-downsampled.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching(eeg_data):\n",
    "    events, event_dict = mne.events_from_annotations(eeg_data)\n",
    "    event_id = event_dict[\"Stimulus/S  1\"]\n",
    "    epochs = mne.Epochs(\n",
    "        eeg_data,\n",
    "        events,\n",
    "        event_id=event_id,\n",
    "        tmin=-1,\n",
    "        tmax=1,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "    )\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 150 events and 2001 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs = epoching(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demeaning/detrending\n",
    "\n",
    "Demeaning is achieved by subtracting each value from each electrode with the average value of the corresponding electrode, essentially bringing the means from all electrodes to 0.\n",
    "\n",
    "> TODO: check if other way of demeaning on complete electrode is possible to move value near 0 or better yet on 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean(eeg_data):\n",
    "    eeg_data.apply_function(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "demean(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mean: 4.555708509534314e-20\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 301 original time points ...\n",
      "1 bad epochs dropped\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 150 events and 101 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "data = spTEP_copy.get_data()\n",
    "mean_values = np.mean(data, axis=1)\n",
    "total_mean = np.mean(mean_values)\n",
    "print(f\"Total mean: {total_mean}\")\n",
    "\n",
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_epochs(epochs):\n",
    "    data = epochs.get_data()\n",
    "    demeaned_data = data - np.mean(data, axis=2, keepdims=True)\n",
    "    demeaned_epochs = mne.EpochsArray(\n",
    "        demeaned_data, epochs.info, events=epochs.events, event_id=epochs.event_id\n",
    "    )\n",
    "    return demeaned_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\3590353875.py:2: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "epochs = demean_epochs(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two graphs with demeaning applied to both the full electrode and to individual epochs. Clearly, there has to be some error in demeaning the full electrode, as those averages aren't close enough to 0. However, when printing the mean values of the electrodes they are indeed close to 0 (e.g. 1\\*e-20). For now, as the demeaned epochs are the desired result, the epochs will be used for further cleaning.\n",
    "\n",
    "![](img/average-demean.png)\n",
    "![](img/average_epoch_demeaned.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA - 1\n",
    "\n",
    "The first ICA filter is mainly to remove the primary large artifacts such as muscle and electrical charge. If demeaning were applied now, a graph as below is the result.\n",
    "\n",
    "This is implemented by first fitting ICA to the signal, and then applying the threshold formula used by the TESA software to each component to either keep or remove each ICA component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_1(epoch_data, T=3.5, b1=0.011, b2=0.030, n_components=20):\n",
    "    ica = ICA(n_components=n_components, random_state=97)\n",
    "    ica.fit(epoch_data)\n",
    "\n",
    "    # Credits to Arne Callaert for the following code\n",
    "    sources = ica.get_sources(epoch_data)\n",
    "    averaged_sources = sources.get_data().mean(axis=0)\n",
    "    times = sources.times\n",
    "    sfreq = sources.info[\"sfreq\"]\n",
    "    indices = np.where((times >= (b1 / 1000)) & (times <= (b2 / 1000)))\n",
    "    print(\"indices:\", indices)\n",
    "    components_to_remove = []\n",
    "\n",
    "    for i, component in enumerate(averaged_sources):\n",
    "        base = len(times) / 2\n",
    "        b1_index = int(base + (b1 * sfreq))\n",
    "        b2_index = int(base + (b2 * sfreq))\n",
    "        x = np.mean(np.abs(component[b1_index:b2_index]))\n",
    "        y = np.mean(np.abs(component))\n",
    "        if x / y > T:\n",
    "            print(\"FOUND:\", x / y)\n",
    "            components_to_remove.append(i)\n",
    "\n",
    "    ica.exclude = components_to_remove\n",
    "\n",
    "    epoch_data = ica.apply(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 62 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\1222509230.py:3: RuntimeWarning: The data has not been high-pass filtered. For good ICA performance, it should be high-pass filtered (e.g., with a 1.0 Hz lower bound) before fitting ICA.\n",
      "  ica.fit(epoch_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 20 components\n",
      "Fitting ICA took 14.1s.\n",
      "indices: (array([], dtype=int64),)\n",
      "FOUND: 4.587167828341068\n",
      "FOUND: 5.067458493528216\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (20 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 62 PCA components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\1222509230.py:7: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  averaged_sources = sources.get_data().mean(axis=0)\n"
     ]
    }
   ],
   "source": [
    "ICA_1(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch_ica_1.png)\n",
    "The graph below shows the result after applying the ICA filter. However, this looks like it results in muddier values than before. The goal was to filter out the initial peak values, residue from the TMS pulse, but these are still present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass - Notch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_notch(epoch_data, low_freq=1, high_freq=100, notch_freqs=[50]):\n",
    "    # Bandpass\n",
    "    epoch_data.filter(low_freq, high_freq)\n",
    "\n",
    "    # Notch (only directly available on raw object, not on epochs)\n",
    "    data = epoch_data.get_data()\n",
    "    notch_filtered = mne.filter.notch_filter(data, epochs.info[\"sfreq\"], notch_freqs)\n",
    "    filtered_epochs = mne.epochs.EpochsArray(\n",
    "        notch_filtered, epochs.info, events=epochs.events, tmin=epochs.tmin\n",
    "    )\n",
    "\n",
    "    return filtered_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\1926252352.py:3: RuntimeWarning: filter_length (3301) is longer than the signal (2001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epoch_data.filter(low_freq, high_freq)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done 4607 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 5201 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=1)]: Done 5831 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=1)]: Done 6497 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=1)]: Done 7937 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=1)]: Done 8711 tasks      | elapsed:    5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\1926252352.py:6: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epoch_data.get_data()\n",
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\1926252352.py:7: RuntimeWarning: filter_length (6601) is longer than the signal (2001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  notch_filtered = mne.filter.notch_filter(data, epochs.info[\"sfreq\"], notch_freqs)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 4607 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done 5201 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=1)]: Done 5831 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=1)]: Done 6497 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=1)]: Done 7937 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done 8711 tasks      | elapsed:    4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs = bandpass_notch(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch_filter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rereference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereference(epochs):\n",
    "    mne.set_eeg_reference(epochs, ref_channels=\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "rereference(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch_rereference.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA - 2\n",
    "\n",
    "Li et al., (2022). MNE-ICALabel: Automatically annotating ICA components with ICLabel in Python. Journal of Open Source Software, 7(76), 4484, https://doi.org/10.21105/joss.04484\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_2(epoch_data):\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=42)\n",
    "    ica.fit(epoch_data)\n",
    "    ic_labels = label_components(epoch_data, ica, method=\"iclabel\")\n",
    "\n",
    "    print(ic_labels[\"labels\"])\n",
    "\n",
    "    labels = ic_labels[\"labels\"]\n",
    "    exclude_idx = [\n",
    "        idx for idx, label in enumerate(labels) if label not in [\"brain\", \"other\"]\n",
    "    ]\n",
    "    print(f\"Excluding these {len(exclude_idx)} ICA components: {exclude_idx}\")\n",
    "\n",
    "    ica.apply(epoch_data, exclude=exclude_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_copy = epochs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 62 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 10.2s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\739043385.py:4: RuntimeWarning: The provided Epochs instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(epoch_data, ica, method=\"iclabel\")\n",
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\739043385.py:4: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(epoch_data, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "['other', 'eye blink', 'brain', 'muscle artifact', 'brain', 'brain', 'brain', 'eye blink', 'brain', 'brain', 'muscle artifact', 'brain', 'muscle artifact', 'muscle artifact', 'muscle artifact', 'other', 'other', 'muscle artifact', 'muscle artifact', 'muscle artifact']\n",
      "Excluding these 10 ICA components: [1, 3, 7, 10, 12, 13, 14, 17, 18, 19]\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (20 components)\n",
      "    Zeroing out 10 ICA components\n",
      "    Projecting back using 62 PCA components\n"
     ]
    }
   ],
   "source": [
    "ICA_2(epochs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ica 2 result](img/average_epoch_ica_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(epoch_data):\n",
    "    epoch_data.apply_baseline((None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "baseline(epochs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\696622896.py:20: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_average_epoch(epochs_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch_baseline.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_average_epoch(epochs, start=-0.05, end=0.2):\n",
    "    data = epochs.get_data()\n",
    "    mean_responses = np.mean(data, axis=(0, 1))\n",
    "    sem_responses = np.std(data, axis=(0, 1)) / np.sqrt(data.shape[0])\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    selected_data = mean_responses[selected_indices]\n",
    "    selected_sem = sem_responses[selected_indices]\n",
    "    selected_time_points = time_points[selected_indices]\n",
    "    plt.plot(selected_time_points, selected_data, label=\"Average of all electrodes\")\n",
    "    plt.fill_between(\n",
    "        selected_time_points,\n",
    "        selected_data - selected_sem,\n",
    "        selected_data + selected_sem,\n",
    "        color=\"b\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result\n",
    "\n",
    "In these final plots, the total average is plotted with the error range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\352732209.py:2: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "plot_full_average_epoch(epochs_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/average_epoch_all_electrodes.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomas\\AppData\\Local\\Temp\\ipykernel_25448\\336539433.py:1: RuntimeWarning: tmin is not in time interval. tmin is set to <class 'mne.epochs.EpochsArray'>.tmin (0 s)\n",
      "  epochs_crop = epochs_copy.copy().crop(tmin=-0.05, tmax=0.2).average()\n"
     ]
    }
   ],
   "source": [
    "epochs_crop = epochs_copy.copy().crop(tmin=-0.05, tmax=0.2).average()\n",
    "\n",
    "# Time point to plot (in seconds)\n",
    "time_point = 0.1  # for example\n",
    "\n",
    "# Plot topomap\n",
    "evoked.plot_topomap(times=[0.1], size=3, show_names=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the epochs to a file\n",
    "epochs_copy.save(\"processed_epochs-epo.fif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Current biggest things to find out:\n",
    "\n",
    "- is there a way to further improve the filtering that ICA 1 is supposed to achieve? (Filtering out the residue of the TMS pulse)\n",
    "- how can time ranges be plot on the scalp topography? like in the comparative paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning - rsEEG\n",
    "\n",
    "Cleaning regular EEG data has similar steps to spTEP data, as it uses the same capturing techniques, but doesn't have to deal with TMS related artifacts and doesn't have the event data from TMS pulses. The most important filtering method used here is ICA filtering using the `mne_icalabel` library, paired with bandpass filtering, notch filtering and rereferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rsEEG_pre_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rsEEG_copy \u001b[38;5;241m=\u001b[39m \u001b[43mrsEEG_pre_raw\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rsEEG_pre_raw' is not defined"
     ]
    }
   ],
   "source": [
    "rsEEG_copy = rsEEG_pre_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove EOG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_EOG(rsEEG_pre_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample(rsEEG_pre_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass & notch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rereference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
