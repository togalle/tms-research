{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/conda/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: mne-features in /opt/conda/lib/python3.11/site-packages (0.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from mne) (3.1.4)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from mne) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from mne) (24.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.7.1 in /opt/conda/lib/python3.11/site-packages (from mne) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from mne) (4.66.4)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from mne-features) (0.59.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from mne-features) (1.5.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.11/site-packages (from mne-features) (1.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from mne-features) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.5.0->mne) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->mne) (2.1.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->mne-features) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->mne-features) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->mne-features) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->mne-features) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->mne-features) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog\n",
      "Successfully installed colorlog-6.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mne mne-features colorlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import mne_features\n",
    "\n",
    "import utils\n",
    "logger = utils.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fif_file(filename):\n",
    "    eeg_data = mne.read_epochs(filename)\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_s1b_rsEEG_pre-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "317 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_S1b_spTEP_post-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "<class 'mne.epochs.EpochsFIF'>\n"
     ]
    }
   ],
   "source": [
    "rsEEG = load_fif_file(\"dataset-cleaned/TMS-EEG-H_02_s1b_rsEEG_pre-epo.fif\")\n",
    "spTEP = load_fif_file(\"dataset-cleaned/TMS-EEG-H_02_S1b_spTEP_post-epo.fif\")\n",
    "\n",
    "print(type(rsEEG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label file generator\n",
    "\n",
    "Create one file containing the labels for all files, as labels are file related and would just be duplicated in every line of the csv of the corresponding file. This save storage and keeps a structured overview and seperation of features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-06-11 17:35:26,194] - INFO - Added entry to labels.csv: TMS-EEG-H_02_S1b_rsEEG_post-epo.fif, itbs, 02, rsEEG, post\u001b[0m\n",
      "\u001b[32m[2024-06-11 17:35:26,195] - INFO - Added entry to labels.csv: TMS-EEG-H_02_s1b_rsEEG_pre-epo.fif, itbs, 02, rsEEG, pre\u001b[0m\n",
      "\u001b[32m[2024-06-11 17:35:26,196] - INFO - Added entry to labels.csv: TMS-EEG-H_02_S1b_spTEP_pre-epo.fif, itbs, 02, spTEP, pre\u001b[0m\n",
      "\u001b[32m[2024-06-11 17:35:26,196] - INFO - Added entry to labels.csv: TMS-EEG-H_02_S1b_spTEP_post-epo.fif, itbs, 02, spTEP, post\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def create_labels_csv(directory, metadata_csv, output_csv):\n",
    "    metadata = pd.read_csv(metadata_csv, index_col=0, header=None)\n",
    "\n",
    "    labels = {0: 'sham', 1: 'ctbs', 2: 'itbs'}\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        # note that the s can be upper or lower case and that the letter b can be behind the session number\n",
    "        match = re.match(r'TMS-EEG-H_(\\d+)_(S|s)(\\w+)(b?)_(rsEEG|spTEP)_(pre|post)-epo.fif', filename)\n",
    "        if match:\n",
    "            patient_id, _, session, _, eeg_type, pre_post = match.groups()\n",
    "            session = int(session.rstrip('b'))\n",
    "\n",
    "            # Get the procedure for the session from the metadata\n",
    "            procedure = labels[metadata.loc[f'H{patient_id}'][session]]\n",
    "\n",
    "            data.append([filename, procedure, patient_id, eeg_type, pre_post])\n",
    "            logger.info(f'Added entry to labels.csv: {filename}, {procedure}, {patient_id}, {eeg_type}, {pre_post}')\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['filename', 'procedure', 'patient_id', 'eeg_type', 'pre_post'])\n",
    "    df.to_csv(output_csv, index=False, sep=\";\")\n",
    "    \n",
    "create_labels_csv(\"dataset-cleaned\", \"Randomisatielijst.csv\", \"labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `mne_features` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open fif file\n",
    "def load_fif_file(filename):\n",
    "    eeg_data = mne.read_epochs(filename)\n",
    "    return eeg_data\n",
    "\n",
    "# Extract features from epochs file\n",
    "def get_features(epochs):\n",
    "    \"\"\"Extract features from epochs, returns a dictionary mapping feature names to values.\"\"\"\n",
    "    return {\"mean\": 2}\n",
    "\n",
    "# Save features to csv file\n",
    "def save_features(features, filename):\n",
    "    \"\"\"Save features to a csv file from a dataframe.\"\"\"\n",
    "    pd.DataFrame.to_csv()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_s1b_rsEEG_pre-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "317 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_S1b_rsEEG_post-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-06-12 17:18:19,644] - INFO - Extracting features: ['variance', 'std']\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,492] - INFO - Feature shape: (296, 124)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,493] - INFO - Reshaping features to dictionary\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,494] - INFO - Reshaped feature shape: (296, 2, 62)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,494] - INFO - Transforming dictionary to dataframe\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,495] - INFO - Normalizing features\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:20,500] - INFO - Saving features to csv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_s1b_rsEEG_pre-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "317 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-06-12 17:18:21,830] - INFO - Extracting features: ['variance', 'std']\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,632] - INFO - Feature shape: (317, 124)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,633] - INFO - Reshaping features to dictionary\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,633] - INFO - Reshaped feature shape: (317, 2, 62)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,634] - INFO - Transforming dictionary to dataframe\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,635] - INFO - Normalizing features\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:22,641] - INFO - Saving features to csv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_S1b_spTEP_pre-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-06-12 17:18:22,899] - INFO - Extracting features: ['variance', 'std']\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,144] - INFO - Feature shape: (150, 124)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,144] - INFO - Reshaping features to dictionary\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,145] - INFO - Reshaped feature shape: (150, 2, 62)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,145] - INFO - Transforming dictionary to dataframe\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,146] - INFO - Normalizing features\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,150] - INFO - Saving features to csv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/tomasgalle/UGent/thesis/tms-research/dataset-cleaned/TMS-EEG-H_02_S1b_spTEP_post-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-06-12 17:18:23,366] - INFO - Extracting features: ['variance', 'std']\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,657] - INFO - Feature shape: (149, 124)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,658] - INFO - Reshaping features to dictionary\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,658] - INFO - Reshaped feature shape: (149, 2, 62)\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,659] - INFO - Transforming dictionary to dataframe\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,660] - INFO - Normalizing features\u001b[0m\n",
      "\u001b[32m[2024-06-12 17:18:23,665] - INFO - Saving features to csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# List of features to extract\n",
    "# mean is useless because of the rereferencing to the average\n",
    "# takes long to calculate: app entropy\n",
    "# wavelet coef energy: 6 * channels\n",
    "selected_funcs = [\n",
    "    \"variance\",\n",
    "    \"std\",\n",
    "    # \"ptp_amp\",\n",
    "    # \"skewness\",\n",
    "    # \"kurtosis\",\n",
    "    # \"rms\",\n",
    "    # \"hjorth_mobility\",\n",
    "    # \"hjorth_complexity\",\n",
    "    # \"zero_crossings\",\n",
    "    # \"line_length\",\n",
    "    # \"app_entropy\",\n",
    "    # \"hurst_exp\",\n",
    "    # ==============\n",
    "    # \"pow_freq_bands\",\n",
    "    # \"wavelet_coef_energy\",\n",
    "    # \"spect_slope\",\n",
    "    # \"spect_entropy\",\n",
    "    ]\n",
    "\n",
    "def epochs_to_feature_csv(epochs, selected_funcs, output_csv):\n",
    "    # Extract features\n",
    "    logger.info(f\"Extracting features: {selected_funcs}\")\n",
    "    rsEEG_feat = mne_features.feature_extraction.extract_features(epochs.get_data(copy=True), sfreq=epochs.info[\"sfreq\"], selected_funcs=selected_funcs, n_jobs=2) # shape (num_epochs, num_features * num_channels)\n",
    "\n",
    "    logger.info(f\"Feature shape: {rsEEG_feat.shape}\")\n",
    "\n",
    "    # Fit features to dictionary\n",
    "    logger.info(\"Reshaping features to dictionary\")\n",
    "    num_epochs, num_features_times_channels = rsEEG_feat.shape\n",
    "    num_channels = len(epochs.ch_names)\n",
    "    num_features = len(selected_funcs)\n",
    "    rsEEG_feat_reshaped = rsEEG_feat.reshape(num_epochs, num_features, num_channels)\n",
    "    logger.info(f\"Reshaped feature shape: {rsEEG_feat_reshaped.shape}\")\n",
    "    feature_dict = {} # Each entry has shape (num_epochs, num_channels * num_features)\n",
    "    for i, feature in enumerate(selected_funcs):\n",
    "        feature_dict[feature] = rsEEG_feat_reshaped[:, i, :]\n",
    "\n",
    "    # Save features to dataframe\n",
    "    logger.info(\"Transforming dictionary to dataframe\")\n",
    "    df_list = [pd.DataFrame(feature_dict[key]) for key in feature_dict]\n",
    "    df = pd.concat(df_list, axis=1, keys=feature_dict.keys())\n",
    "\n",
    "    # Normalize features\n",
    "    logger.info(\"Normalizing features\")\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    for feature in df.columns.levels[0]:\n",
    "        df[feature] = scaler.fit_transform(df[feature])\n",
    "\n",
    "    # Save features to csv\n",
    "    logger.info(\"Saving features to csv\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "def feat_extr_on_folder(source_folder, destination_folder):\n",
    "    # Make sure the folder for csv files exists\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith(\".fif\"):\n",
    "            eeg_data = load_fif_file(os.path.join(source_folder, filename))\n",
    "            epochs_to_feature_csv(eeg_data, selected_funcs, os.path.join(destination_folder, f\"{filename}.csv\"))\n",
    "            \n",
    "feat_extr_on_folder(\"dataset-cleaned\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap\n",
    "## rsEEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical features\n",
    "- Mean\n",
    "- STD\n",
    "- Peak amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dict(eeg_data):\n",
    "    data = eeg_data.get_data()\n",
    "    ch_names = eeg_data.info['ch_names']\n",
    "    avg_values = np.mean(data, axis=1)\n",
    "    electrode_avg_dict = dict(zip(ch_names, avg_values))\n",
    "    return electrode_avg_dict\n",
    "\n",
    "def total_mean(mean_dict, electrodes=None):\n",
    "    if electrodes is None:\n",
    "        return np.mean(list(mean_dict.values()))\n",
    "    else:\n",
    "        return np.mean([mean_dict[electrode] for electrode in electrodes])\n",
    "    \n",
    "def std_dict(eeg_data):\n",
    "    data = eeg_data.get_data()\n",
    "    ch_names = eeg_data.info['ch_names']\n",
    "    std_values = np.std(data, axis=1)\n",
    "    electrode_std_dict = dict(zip(ch_names, std_values))\n",
    "    return electrode_std_dict\n",
    "\n",
    "def total_std(std_dict, electrodes=None):\n",
    "    if electrodes is None:\n",
    "        return np.mean(list(std_dict.values()))\n",
    "    else:\n",
    "        return np.mean([std_dict[electrode] for electrode in electrodes])\n",
    "    \n",
    "def peak_dict(eeg_data):\n",
    "    data = eeg_data.get_data()\n",
    "    ch_names = eeg_data.info['ch_names']\n",
    "    peak_values = np.max(data, axis=1)\n",
    "    electrode_peak_dict = dict(zip(ch_names, peak_values))\n",
    "    return electrode_peak_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean dict: \", mean_dict(rsEEG))\n",
    "print(\"Total mean: \", total_mean(mean_dict(rsEEG)))\n",
    "print(\"STD dict: \", std_dict(rsEEG))\n",
    "print(\"Total STD: \", total_std(std_dict(rsEEG)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsEEG.compute_psd(fmin=0.5, fmax=100, n_fft=2048, n_overlap=1024, verbose=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
