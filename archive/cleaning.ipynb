{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mne-icalabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import utils\n",
    "\n",
    "# Specify graph rendering method\n",
    "# %matplotlib widget\n",
    "plt.switch_backend(\"TkAgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ./dataset/TMS-EEG-H_02_S1b_spTEP_pre.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 2696199  =      0.000 ...   539.240 secs...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n",
      "Extracting parameters from ./dataset/TMS-EEG-H_02_S1b_rsEEG_pre.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 3984899  =      0.000 ...   796.980 secs...\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"./dataset\"\n",
    "FILENAME_TEMPLATE = \"TMS-EEG-H_02_S1b_{}_{}.vhdr\"\n",
    "\n",
    "spTEP_pre_raw = mne.io.read_raw_brainvision(\n",
    "    os.path.join(DATASET_PATH, FILENAME_TEMPLATE.format(\"spTEP\", \"pre\")), preload=True\n",
    ")\n",
    "sampling_rate = spTEP_pre_raw.info[\"sfreq\"]\n",
    "events, event_dict = mne.events_from_annotations(spTEP_pre_raw)\n",
    "tms_indices = [event[0] for event in events if event[2] == 1]\n",
    "\n",
    "rsEEG_pre_raw = mne.io.read_raw_brainvision(\n",
    "    os.path.join(DATASET_PATH, FILENAME_TEMPLATE.format(\"rsEEG\", \"pre\")), preload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utilities\n",
    "def plot_single_response(eeg_data, channel=\"Pz\", tmin=-0.005, tmax=0.01):\n",
    "    events, event_dict = mne.events_from_annotations(eeg_data)\n",
    "    event_id = event_dict[\"Stimulus/S  1\"]\n",
    "    epochs = mne.Epochs(\n",
    "        eeg_data,\n",
    "        events,\n",
    "        event_id=event_id,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "        picks=channel,\n",
    "    )\n",
    "\n",
    "    epochs.plot(picks=channel, n_epochs=1, show=True, scalings={\"eeg\": 50e-4})\n",
    "\n",
    "\n",
    "def plot_average_epoch(epochs, start=-0.05, end=0.25):\n",
    "    data = epochs.get_data()\n",
    "    mean_responses = np.mean(data, axis=0)\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    for i, mean_response in enumerate(mean_responses):\n",
    "        selected_data = mean_response[selected_indices]\n",
    "        selected_time_points = time_points[selected_indices]\n",
    "        plt.plot(selected_time_points, selected_data, label=f\"Channel {i+1}\")\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_response(eeg):\n",
    "    utils.plot_average_response(eeg, tmin=-0.05, tmax=0.25)  # Check full response\n",
    "    utils.plot_single_response(\n",
    "        eeg, channel=\"Pz\", tmin=-0.05, tmax=0.05\n",
    "    )  # Check for TMS pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning - spTEP\n",
    "\n",
    "The paper of Bertazzoli et al. (2021) compares 4 pipelines: ARTIST, TMSEEG, TESA and SOUND-SSP-SIR, all of which work decently well in varying degrees. There are common steps, but TESA will be the one that will be most closely followed. The current steps are as follows:\n",
    "\n",
    "1. Remove EOG\n",
    "2. Remove TMS pulse\n",
    "3. Downsample\n",
    "4. **ICA - 1**\n",
    "5. Bandpass - Notch filters\n",
    "6. **ICA - 2**\n",
    "7. Rereference\n",
    "\n",
    "Currently, there is no demeaning or bad channel rejection present as in TESA. Demeaning is done before the TMS-pulse interpolation, and baseline correction should be done as last step after rereferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_response(spTEP_pre_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/raw-average.png)\n",
    "![](img/single-pulse-raw.JPG)\n",
    "\n",
    "The figure above already shows 2 major artifacts that cleaning will have the biggest impact on: TMS-pulse interpolation and demeaning/baseline correction. The major TMS-pulse artifact falls closely within the range of 2ms before until 5ms after the pulse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spTEP_copy = spTEP_pre_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOG removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_EOG(eeg_data):\n",
    "    eeg_data.drop_channels([\"HEOG\", \"VEOG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_EOG(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMS pulse removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_range_indices(tms_index, start, end, sampling_rate):\n",
    "    \"\"\"\n",
    "    start and end are positive in seconds\n",
    "    sampling rate in Hz\n",
    "    \"\"\"\n",
    "    samples_before = int(start * sampling_rate)\n",
    "    samples_after = int(end * sampling_rate)\n",
    "\n",
    "    start_index = max(0, tms_index - samples_before)\n",
    "    end_index = tms_index + samples_after\n",
    "\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_TMS_pulse(eeg_data_raw, tms_indices, start, end, sampling_rate):\n",
    "    eeg_data = eeg_data_raw.get_data()\n",
    "    num_electrodes = eeg_data.shape[0]\n",
    "    for tms_index in tms_indices:\n",
    "        start_index, end_index = calculate_range_indices(\n",
    "            tms_index, start, end, sampling_rate\n",
    "        )\n",
    "        for i in range(num_electrodes):\n",
    "            x = [start_index - 2, start_index - 1, end_index + 1, end_index + 2]\n",
    "            y = [\n",
    "                eeg_data[i, start_index - 2],\n",
    "                eeg_data[i, start_index - 1],\n",
    "                eeg_data[i, end_index + 1],\n",
    "                eeg_data[i, end_index + 2],\n",
    "            ]\n",
    "            x_new = np.arange(start_index, end_index + 1)\n",
    "\n",
    "            interp_func = interp1d(x, y, kind=\"cubic\")\n",
    "            eeg_data[i, start_index : end_index + 1] = interp_func(x_new)\n",
    "\n",
    "    eeg_data_raw._data = eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_TMS_pulse(\n",
    "    spTEP_copy, tms_indices, 0.005, 0.01, sampling_rate\n",
    ")  # 2ms before, 5ms after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/interpolated-average.png)\n",
    "![](img/interpolation-5-10/single-pulse-interpolated.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This succesfully removed the TMS pulse artifact by using cubic interpolation based on the 2 values before and 2 values after the range that is to be interpolated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "The original data was captured with a sampling frequency of 5000 Hz. 1000 Hz is chosen as the frequency to be downsampled to, as this means that, following Nyquists theorem, the highest frequency that will be accurately recorded is 500 Hz, which should be more than enough for further analysis, as the gamma band is often referred to as 30-100 Hz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(eeg_data, sample_rate=1000):\n",
    "    eeg_data.resample(sample_rate, npad=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/single-downsampled.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching(eeg_data):\n",
    "    events, event_dict = mne.events_from_annotations(eeg_data)\n",
    "    event_id = event_dict[\"Stimulus/S  1\"]\n",
    "    epochs = mne.Epochs(\n",
    "        eeg_data,\n",
    "        events,\n",
    "        event_id=event_id,\n",
    "        tmin=-1,\n",
    "        tmax=1,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "    )\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epoching(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demeaning/detrending\n",
    "\n",
    "Demeaning is achieved by subtracting each value from each electrode with the average value of the corresponding electrode, essentially bringing the means from all electrodes to 0.\n",
    "\n",
    "> TODO: check if other way of demeaning on complete electrode is possible to move value near 0 or better yet on 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean(eeg_data):\n",
    "    eeg_data.apply_function(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demean(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spTEP_copy.get_data()\n",
    "mean_values = np.mean(data, axis=1)\n",
    "total_mean = np.mean(mean_values)\n",
    "print(f\"Total mean: {total_mean}\")\n",
    "\n",
    "plot_response(spTEP_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_epochs(epochs):\n",
    "    data = epochs.get_data()\n",
    "    demeaned_data = data - np.mean(data, axis=2, keepdims=True)\n",
    "    demeaned_epochs = mne.EpochsArray(\n",
    "        demeaned_data, epochs.info, events=epochs.events, event_id=epochs.event_id\n",
    "    )\n",
    "    return demeaned_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = demean_epochs(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two graphs with demeaning applied to both the full electrode and to individual epochs. Clearly, there has to be some error in demeaning the full electrode, as those averages aren't close enough to 0. However, when printing the mean values of the electrodes they are indeed close to 0 (e.g. 1\\*e-20). For now, as the demeaned epochs are the desired result, the epochs will be used for further cleaning.\n",
    "\n",
    "![](img/interpolation-5-10/average-demean.png)\n",
    "![](img/interpolation-5-10/average_epoch_demeaned.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA - 1\n",
    "\n",
    "The first ICA filter is mainly to remove the primary large artifacts such as muscle and electrical charge. If demeaning were applied now, a graph as below is the result.\n",
    "\n",
    "This is implemented by first fitting ICA to the signal, and then applying the threshold formula used by the TESA software to each component to either keep or remove each ICA component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_1(epoch_data, T=3.5, b1=0.011, b2=0.030, n_components=20):\n",
    "    ica = ICA(n_components=n_components, random_state=97)\n",
    "    ica.fit(epoch_data)\n",
    "\n",
    "    # Credits to Arne Callaert for the following code\n",
    "    sources = ica.get_sources(epoch_data)\n",
    "    averaged_sources = sources.get_data().mean(axis=0)\n",
    "    times = sources.times\n",
    "    sfreq = sources.info[\"sfreq\"]\n",
    "    indices = np.where((times >= (b1 / 1000)) & (times <= (b2 / 1000)))\n",
    "    print(\"indices:\", indices)\n",
    "    components_to_remove = []\n",
    "\n",
    "    for i, component in enumerate(averaged_sources):\n",
    "        base = len(times) / 2\n",
    "        b1_index = int(base + (b1 * sfreq))\n",
    "        b2_index = int(base + (b2 * sfreq))\n",
    "        x = np.mean(np.abs(component[b1_index:b2_index]))\n",
    "        y = np.mean(np.abs(component))\n",
    "        if x / y > T:\n",
    "            print(\"FOUND:\", x / y)\n",
    "            components_to_remove.append(i)\n",
    "\n",
    "    ica.exclude = components_to_remove\n",
    "\n",
    "    epoch_data = ica.apply(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_1(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch_ica_1.png)\n",
    "The graph below shows the result after applying the ICA filter. However, this looks like it results in muddier values than before. The goal was to filter out the initial peak values, residue from the TMS pulse, but these are still present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass - Notch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_notch(epoch_data, low_freq=1, high_freq=100, notch_freqs=[50]):\n",
    "    # Bandpass\n",
    "    epoch_data.filter(low_freq, high_freq)\n",
    "\n",
    "    # Notch (only directly available on raw object, not on epochs)\n",
    "    data = epoch_data.get_data()\n",
    "    notch_filtered = mne.filter.notch_filter(data, epochs.info[\"sfreq\"], notch_freqs)\n",
    "    filtered_epochs = mne.epochs.EpochsArray(\n",
    "        notch_filtered, epochs.info, events=epochs.events, tmin=epochs.tmin\n",
    "    )\n",
    "\n",
    "    return filtered_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = bandpass_notch(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch_filter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rereference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereference(epochs):\n",
    "    mne.set_eeg_reference(epochs, ref_channels=\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rereference(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch_rereference.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA - 2\n",
    "\n",
    "Li et al., (2022). MNE-ICALabel: Automatically annotating ICA components with ICLabel in Python. Journal of Open Source Software, 7(76), 4484, https://doi.org/10.21105/joss.04484\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_2(epoch_data):\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=42)\n",
    "    ica.fit(epoch_data)\n",
    "    ic_labels = label_components(epoch_data, ica, method=\"iclabel\")\n",
    "\n",
    "    print(ic_labels[\"labels\"])\n",
    "\n",
    "    labels = ic_labels[\"labels\"]\n",
    "    exclude_idx = [\n",
    "        idx for idx, label in enumerate(labels) if label not in [\"brain\", \"other\"]\n",
    "    ]\n",
    "    print(f\"Excluding these {len(exclude_idx)} ICA components: {exclude_idx}\")\n",
    "\n",
    "    ica.apply(epoch_data, exclude=exclude_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_copy = epochs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_2(epochs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ica 2 result](img/interpolation-5-10/average_epoch_ica_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(epoch_data):\n",
    "    epoch_data.apply_baseline((None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline(epochs_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_epoch(epochs_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch_baseline.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spTEP_pre_copy = spTEP_pre_raw.copy()\n",
    "remove_EOG(spTEP_pre_copy)\n",
    "\n",
    "spTEP_pre_copy.compute_psd().plot_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spTEP_pre_raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_average_epoch(epochs, electrodes=None, start=-0.05, end=0.25):\n",
    "    epochs = epochs.copy()\n",
    "    if electrodes is not None:\n",
    "        epochs.pick_channels(electrodes)\n",
    "    data = epochs.get_data()\n",
    "    mean_responses = np.mean(data, axis=(0, 1))\n",
    "    sem_responses = np.std(data, axis=(0, 1)) / np.sqrt(data.shape[0])\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    selected_data = mean_responses[selected_indices]\n",
    "    selected_sem = sem_responses[selected_indices]\n",
    "    selected_time_points = time_points[selected_indices]\n",
    "    plt.plot(selected_time_points, selected_data, label=\"Average of all electrodes\")\n",
    "    plt.fill_between(\n",
    "        selected_time_points,\n",
    "        selected_data - selected_sem,\n",
    "        selected_data + selected_sem,\n",
    "        color=\"b\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result\n",
    "\n",
    "In these final plots, the total average is plotted with the error range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F, FC\n",
    "# 3, 5, 7\n",
    "\n",
    "plot_full_average_epoch(epochs_copy, end=0.3)\n",
    "plot_full_average_epoch(epochs_copy, ['F3', 'FC5', 'FC1'], end=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/interpolation-5-10/average_epoch_all_electrodes.png)\n",
    "![](img/interpolation-5-10/final-local.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the epochs to a file\n",
    "epochs_copy.save(\"processed_epochs-epo.fif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Current biggest things to find out:\n",
    "\n",
    "- is there a way to further improve the filtering that ICA 1 is supposed to achieve? (Filtering out the residue of the TMS pulse)\n",
    "- how can time ranges be plot on the scalp topography? like in the comparative paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning - rsEEG\n",
    "\n",
    "Cleaning regular EEG data has similar steps to spTEP data, as it uses the same capturing techniques, but doesn't have to deal with TMS related artifacts and doesn't have the event data from TMS pulses. The most important filtering method used here is ICA filtering using the `mne_icalabel` library, paired with bandpass filtering, notch filtering and rereferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_std(eeg_data_raw):\n",
    "    # Get the data\n",
    "    data = eeg_data_raw.get_data()\n",
    "\n",
    "    # Calculate the standard deviation\n",
    "    std = np.std(data, axis=1)\n",
    "\n",
    "    # Calculate the average standard deviation\n",
    "    avg_std = np.mean(std)\n",
    "\n",
    "    return avg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_time_domain(eeg_data_raw, start=0, duration=1, channels=None):\n",
    "    # Get the data and times\n",
    "    eeg_copy = eeg_data_raw.copy()\n",
    "    if channels is not None:\n",
    "        eeg_copy.pick(channels)\n",
    "    data, times = eeg_copy[:, int(start*eeg_copy.info['sfreq']):int((start+duration)*eeg_copy.info['sfreq'])]\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot each channel\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(times, data[i, :], label=eeg_copy.info['ch_names'][i])\n",
    "\n",
    "    # Add y label\n",
    "    plt.ylabel('Voltage (V)')\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsEEG_copy = rsEEG_pre_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.140313e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.6e}\".format(calculate_avg_std(rsEEG_pre_raw)))\n",
    "plot_raw_time_domain(rsEEG_pre_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![raw rsEEG](img/rsEEG/rsEEG_raw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove EOG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_brainvis(eeg_data_raw):\n",
    "    eeg_data_raw.apply_function(lambda x: x - np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass & notch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsEEG_filters(eeg_data, l_freq=1, h_freq=100, notch_freqs=[50]):\n",
    "    eeg_data.filter(l_freq, h_freq)\n",
    "    eeg_data.notch_filter(notch_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsEEG_ICA(eeg_data):\n",
    "    ica = ICA(n_components=20, random_state=97)\n",
    "    ica.fit(eeg_data)\n",
    "    ic_labels = label_components(eeg_data, ica, method=\"iclabel\")\n",
    "    \n",
    "    labels = ic_labels[\"labels\"]\n",
    "    exclude_idx = [\n",
    "        idx for idx, label in enumerate(labels) if label not in [\"brain\", \"other\"]\n",
    "    ]\n",
    "    \n",
    "    print(f\"Excluding ICA components: {exclude_idx}\")\n",
    "    \n",
    "    ica.apply(eeg_data, exclude=exclude_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rereference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsEEG_rereference(eeg_data):\n",
    "    eeg_data.set_eeg_reference(ref_channels=\"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autoreject in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.20.2 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from autoreject) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from autoreject) (1.11.4)\n",
      "Requirement already satisfied: mne>=1.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne[hdf5]>=1.0->autoreject) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from autoreject) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from autoreject) (1.3.2)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from autoreject) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from matplotlib>=3.4.0->autoreject) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (4.66.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (1.8.0)\n",
      "Requirement already satisfied: decorator in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (3.1.2)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (0.3)\n",
      "Requirement already satisfied: defusedxml in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne>=1.0->mne[hdf5]>=1.0->autoreject) (0.7.1)\n",
      "Requirement already satisfied: h5io in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne[hdf5]>=1.0->autoreject) (0.2.2)\n",
      "Requirement already satisfied: pymatreader in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from mne[hdf5]>=1.0->autoreject) (0.0.32)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from scikit-learn>=0.24.2->autoreject) (3.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->autoreject) (1.16.0)\n",
      "Requirement already satisfied: h5py in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from h5io->mne[hdf5]>=1.0->autoreject) (3.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from jinja2->mne>=1.0->mne[hdf5]>=1.0->autoreject) (2.1.3)\n",
      "Requirement already satisfied: xmltodict in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from pymatreader->mne[hdf5]>=1.0->autoreject) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tomasgalle/miniconda3/envs/tms/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0->mne[hdf5]>=1.0->autoreject) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoreject import AutoReject\n",
    "\n",
    "def rsEEG_epoch(eeg_data, duration=2.0, overlap=0.5):\n",
    "    \"\"\"Create an epochs object from the raw brainvision data, where each epoch is 2 seconds long and got baseline corrected using the last 500ms of the previous epoch\n",
    "\n",
    "    Args:\n",
    "        eeg_data (Any): full EEG data\n",
    "    \"\"\"\n",
    "    \n",
    "    overlap *= duration\n",
    "    \n",
    "    events = mne.make_fixed_length_events(eeg_data, duration=duration+overlap, overlap=overlap)\n",
    "    epochs = mne.Epochs(eeg_data, events, baseline=(None, None), tmin=0, tmax=duration, preload=True)\n",
    "    ar = AutoReject()\n",
    "    epochs_clean = ar.fit_transform(epochs)\n",
    "    \n",
    "    return epochs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCOVER-EEG:\n",
    "1. Line noise removal\n",
    "2. Bad channel rejection\n",
    "3. Rereference\n",
    "4. ICA\n",
    "5. Bad channel interpolation\n",
    "6. Bad time segments removal\n",
    "\n",
    "Own pipeline without TMS filtering:\n",
    "1. Remove EOG\n",
    "2. Downsample\n",
    "3. Demeaning\n",
    "4. Bandpass & notch\n",
    "5. ICA\n",
    "6. Rereference\n",
    "7. Epoch & baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 62 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 23.0s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3500229/1449805445.py:4: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(eeg_data, ica, method=\"iclabel\")\n",
      "/tmp/ipykernel_3500229/1449805445.py:4: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(eeg_data, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Excluding ICA components: [0, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18]\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (20 components)\n",
      "    Zeroing out 12 ICA components\n",
      "    Projecting back using 62 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "rsEEG_copy = rsEEG_pre_raw.copy()\n",
    "\n",
    "remove_EOG(rsEEG_copy)\n",
    "downsample(rsEEG_copy)\n",
    "demean_brainvis(rsEEG_copy)\n",
    "rsEEG_filters(rsEEG_copy)\n",
    "rsEEG_ICA(rsEEG_copy)\n",
    "rsEEG_rereference(rsEEG_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "397 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 397 events and 2001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4215518dfde3476690b935f2b18f859d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/62 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acf25b645be41ceb341ceb43be9cc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/62 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc196baa7e9c4c258a6f49d19d8b81df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/397 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ad20ccb54c4005a4cf0a2436724901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | n_interp : 0/3 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcd38ae6d264bc9a30b562c21ca93c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/397 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dee3293e16845bc87bbfff926331ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0f3e893a784cb082fd9857f8a1f175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/397 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e189427ada924efba9c6809d1aa56bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f8101203154e2ba2a3f5d2a342af33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/397 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfc2211b2324d37ba41824d8178a154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimated consensus=0.40 and n_interpolate=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10c0d564a7d4a72967dd334f3aa61f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/397 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 84 epochs: 1, 2, 3, 4, 5, 7, 8, 9, 11, 14, 16, 17, 18, 19, 20, 21, 55, 79, 80, 81, 90, 106, 107, 108, 118, 119, 122, 130, 134, 146, 148, 155, 160, 165, 166, 167, 168, 183, 189, 218, 228, 234, 244, 245, 259, 263, 279, 285, 286, 287, 288, 302, 306, 310, 311, 313, 314, 315, 319, 320, 321, 322, 323, 324, 325, 326, 336, 340, 347, 348, 350, 356, 358, 359, 368, 369, 370, 373, 374, 375, 388, 389, 395, 396\n"
     ]
    }
   ],
   "source": [
    "epochs = rsEEG_epoch(rsEEG_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3500229/3507919554.py:2: RuntimeWarning: This filename (filtered/rsEEG-epochs-cleaned.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs.save(filename, overwrite=True)\n"
     ]
    }
   ],
   "source": [
    "def save_epochs(epochs, filename):\n",
    "    epochs.save(filename, overwrite=True)\n",
    "\n",
    "save_epochs(epochs, 'filtered/rsEEG-epochs-cleaned.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs(filename):\n",
    "    return mne.read_epochs(filename, preload=True)\n",
    "\n",
    "epochs = load_epochs('filtered/rsEEG-epochs-cleaned.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_response(epochs):\n",
    "    # Get the average of all epochs\n",
    "    evoked = epochs.average()\n",
    "\n",
    "    # Plot the average response\n",
    "    evoked.plot(time_unit='s')\n",
    "\n",
    "plot_average_response(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3500229/2068037934.py:6: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gmfa(epochs):\n",
    "    # Get the data from the epochs\n",
    "    data = epochs.get_data()\n",
    "\n",
    "    # Calculate the GMFA\n",
    "    gmfa = np.sqrt(np.mean(data ** 2, axis=1))\n",
    "\n",
    "    # Average the GMFA across all epochs\n",
    "    avg_gmfa = np.mean(gmfa, axis=0)\n",
    "\n",
    "    # Plot the average GMFA\n",
    "    plt.figure()\n",
    "    plt.plot(epochs.times, avg_gmfa)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('GMFA')\n",
    "    plt.show()\n",
    "\n",
    "plot_gmfa(epochs)\n",
    "\n",
    "def plot_total_average(epochs):\n",
    "    # Average all epochs into one epoch\n",
    "    evoked = epochs.average()\n",
    "\n",
    "    # Get the data from the evoked object\n",
    "    data = evoked.data\n",
    "\n",
    "    # Take the average across all channels\n",
    "    total_average = np.mean(data, axis=0)\n",
    "\n",
    "    # Plot the total average\n",
    "    plt.figure()\n",
    "    plt.plot(evoked.times, total_average)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Total Average Response')\n",
    "    plt.show()\n",
    "\n",
    "plot_total_average(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsEEG_cleaning(eeg_data):\n",
    "    remove_EOG(eeg_data)\n",
    "    downsample(eeg_data)\n",
    "    demean_brainvis(eeg_data)\n",
    "    rsEEG_filters(eeg_data)\n",
    "    rsEEG_ICA(eeg_data)\n",
    "    rsEEG_rereference(eeg_data)\n",
    "    epochs = rsEEG_epoch(eeg_data)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_epoch(epochs, start=-0.05, end=0.25, electrodes=None):\n",
    "    epochs = epochs.copy()\n",
    "    if electrodes is not None:\n",
    "        epochs.pick_channels(electrodes)\n",
    "    data = epochs.get_data(copy=False)\n",
    "    mean_responses = np.mean(data, axis=0)\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    for i, mean_response in enumerate(mean_responses):\n",
    "        selected_data = mean_response[selected_indices]\n",
    "        selected_time_points = time_points[selected_indices]\n",
    "        plt.plot(selected_time_points, selected_data, label=f\"Channel {i+1}\")\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_aggregated_average_epoch(epochs, electrodes=None, start=-0.05, end=0.25, plot_gmfp=True):\n",
    "    epochs = epochs.copy()\n",
    "    if electrodes is not None:\n",
    "        epochs.pick_channels(electrodes)\n",
    "    data = epochs.get_data(copy=False)\n",
    "    mean_responses = np.mean(data, axis=(0, 1))\n",
    "    sem_responses = np.std(data, axis=(0, 1)) / np.sqrt(data.shape[0])\n",
    "    time_points = np.linspace(-1, 1, data.shape[2])\n",
    "    selected_indices = np.where((time_points >= start) & (time_points <= end))\n",
    "    selected_data = mean_responses[selected_indices]\n",
    "    selected_sem = sem_responses[selected_indices]\n",
    "    selected_time_points = time_points[selected_indices]\n",
    "    plt.plot(selected_time_points, selected_data, label=\"Average of all electrodes\")\n",
    "    plt.fill_between(\n",
    "        selected_time_points,\n",
    "        selected_data - selected_sem,\n",
    "        selected_data + selected_sem,\n",
    "        color=\"b\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    if plot_gmfp:\n",
    "        data = epochs.get_data()\n",
    "        average_epoch = np.mean(data, axis=0)\n",
    "        # mean = np.mean(average_epoch, axis=0, keepdims=True)\n",
    "        # diff = average_epoch - mean\n",
    "        # squared_diff = np.square(diff)\n",
    "        # sum_squared_diff = np.sum(squared_diff, axis=0)\n",
    "        # gmfp = np.sqrt(sum_squared_diff / average_epoch.shape[0])\n",
    "        \n",
    "        # Calculate the GMFA by taking the standard deviation accross all channels\n",
    "        gmfa = np.std(average_epoch, axis=0)\n",
    "    \n",
    "        # plt.plot(selected_time_points, gmfp[selected_indices], label=\"GMFP\")\n",
    "        plt.plot(selected_time_points, gmfa[selected_indices], label=\"GMFA\")\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Mean response\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 62 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 27.1s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205077/1449805445.py:4: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(eeg_data, ica, method=\"iclabel\")\n",
      "/tmp/ipykernel_3205077/1449805445.py:4: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(eeg_data, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Excluding ICA components: [0, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18]\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (20 components)\n",
      "    Zeroing out 12 ICA components\n",
      "    Projecting back using 62 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Not setting metadata\n",
      "398 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 398 events and 2001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3b9fae715547c395b4f8c73239a4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/62 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d14af5845d4d74ac0e5d7621cf4ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/62 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rsEEG_copy \u001b[38;5;241m=\u001b[39m rsEEG_pre_raw\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[43mrsEEG_cleaning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrsEEG_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plot_average_epoch(epochs)\n",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m, in \u001b[0;36mrsEEG_cleaning\u001b[0;34m(eeg_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m rsEEG_ICA(eeg_data)\n\u001b[1;32m      7\u001b[0m rsEEG_rereference(eeg_data)\n\u001b[0;32m----> 8\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[43mrsEEG_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epochs\n",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m, in \u001b[0;36mrsEEG_epoch\u001b[0;34m(eeg_data, duration, overlap, baseline_start, baseline_end)\u001b[0m\n\u001b[1;32m     11\u001b[0m epochs \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mEpochs(eeg_data, events, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, tmax\u001b[38;5;241m=\u001b[39mduration, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m ar \u001b[38;5;241m=\u001b[39m AutoReject()\n\u001b[0;32m---> 13\u001b[0m epochs_clean \u001b[38;5;241m=\u001b[39m \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epochs_clean\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:1181\u001b[0m, in \u001b[0;36mAutoReject.fit_transform\u001b[0;34m(self, epochs, return_log)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs, return_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate the rejection params and finds bad epochs.\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \n\u001b[1;32m   1165\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;124;03m        The rejection log. Returned only of return_log is True.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(epochs, return_log\u001b[38;5;241m=\u001b[39mreturn_log)\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:1041\u001b[0m, in \u001b[0;36mAutoReject.fit\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning autoreject on ch_type=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ch_type)\n\u001b[1;32m   1040\u001b[0m this_local_reject, this_loss \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 1041\u001b[0m     \u001b[43m_run_local_reject_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_picks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_interpolate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsensus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshes_\u001b[38;5;241m.\u001b[39mupdate(this_local_reject\u001b[38;5;241m.\u001b[39mthreshes_)\n\u001b[1;32m   1047\u001b[0m best_idx, best_jdx \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1048\u001b[0m     np\u001b[38;5;241m.\u001b[39munravel_index(this_loss\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmin(),\n\u001b[1;32m   1049\u001b[0m                      this_loss\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:796\u001b[0m, in \u001b[0;36m_run_local_reject_cv\u001b[0;34m(epochs, thresh_func, picks_, n_interpolate, cv, consensus, dots, verbose)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# The thresholds must be learnt from the entire data\u001b[39;00m\n\u001b[1;32m    793\u001b[0m local_reject \u001b[38;5;241m=\u001b[39m _AutoReject(thresh_func\u001b[38;5;241m=\u001b[39mthresh_func,\n\u001b[1;32m    794\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39mverbose, picks\u001b[38;5;241m=\u001b[39mpicks_,\n\u001b[1;32m    795\u001b[0m                            dots\u001b[38;5;241m=\u001b[39mdots)\n\u001b[0;32m--> 796\u001b[0m \u001b[43mlocal_reject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(local_reject\u001b[38;5;241m.\u001b[39mconsensus_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# works with one ch_type\u001b[39;00m\n\u001b[1;32m    799\u001b[0m ch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(local_reject\u001b[38;5;241m.\u001b[39mconsensus_))\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:710\u001b[0m, in \u001b[0;36m_AutoReject.fit\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_interpolate_[ch_type] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_interpolate\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsensus_[ch_type] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsensus\n\u001b[0;32m--> 710\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresh_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpicks_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m reject_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reject_log(epochs\u001b[38;5;241m=\u001b[39mepochs, picks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpicks_)\n\u001b[1;32m    716\u001b[0m epochs_copy \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:479\u001b[0m, in \u001b[0;36m_compute_thresholds\u001b[0;34m(epochs, method, random_state, picks, augment, dots, verbose, n_jobs)\u001b[0m\n\u001b[1;32m    477\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    478\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing thresholds ...\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 479\u001b[0m     threshes \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmy_thresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpick\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_pbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     threshes \u001b[38;5;241m=\u001b[39m {ch_names[p]: thresh \u001b[38;5;28;01mfor\u001b[39;00m p, thresh \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(picks, threshes)}\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m threshes\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:386\u001b[0m, in \u001b[0;36m_compute_thresh\u001b[0;34m(this_data, method, cv, y, random_state)\u001b[0m\n\u001b[1;32m    384\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(idx)  \u001b[38;5;66;03m# linspace may be non-unique if n_epochs < 40\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     initial_x \u001b[38;5;241m=\u001b[39m all_threshes[idx]\n\u001b[0;32m--> 386\u001b[0m     best_thresh, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbayes_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mall_threshes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mexpected_improvement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_thresh\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/bayesopt.py:45\u001b[0m, in \u001b[0;36mbayes_opt\u001b[0;34m(f, initial_x, all_x, acquisition, max_iter, debug, random_state)\u001b[0m\n\u001b[1;32m     43\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m initial_x:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     46\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(f(x))\n\u001b[1;32m     47\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:376\u001b[0m, in \u001b[0;36m_compute_thresh.<locals>.func\u001b[0;34m(thresh)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m    375\u001b[0m     est\u001b[38;5;241m.\u001b[39mset_params(thresh\u001b[38;5;241m=\u001b[39mthresh)\n\u001b[0;32m--> 376\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    377\u001b[0m     cache\u001b[38;5;241m.\u001b[39mupdate({thresh: obj})\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[thresh]\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:917\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    914\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    916\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 917\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:982\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    980\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:141\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39m_score(\n\u001b[1;32m    138\u001b[0m             cached_call, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mscore\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     scores[name] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:415\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/autoreject/autoreject.py:160\u001b[0m, in \u001b[0;36mBaseAutoReject.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/numpy/lib/function_base.py:3927\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3845\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[1;32m   3846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3848\u001b[0m \u001b[38;5;124;03m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[1;32m   3849\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3925\u001b[0m \n\u001b[1;32m   3926\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_median\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3928\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/numpy/lib/function_base.py:3960\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3958\u001b[0m         part \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3960\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m part\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m   3963\u001b[0m     \u001b[38;5;66;03m# make 0-D arrays work\u001b[39;00m\n\u001b[1;32m   3964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m part\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/tms/lib/python3.12/site-packages/numpy/core/fromnumeric.py:771\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     a \u001b[38;5;241m=\u001b[39m asanyarray(a)\u001b[38;5;241m.\u001b[39mcopy(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 771\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rsEEG_copy = rsEEG_pre_raw.copy()\n",
    "epochs = rsEEG_cleaning(rsEEG_copy)\n",
    "plot_average_epoch(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cleaned rsEEG](img/rsEEG/rsEEG_cleaned.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/tomasgalle/UGent/thesis/tms-research/filtered/rsEEG_cleaned.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1454481/284752700.py:1: RuntimeWarning: This filename (/home/tomasgalle/UGent/thesis/tms-research/filtered/rsEEG_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  rsEEG_copy.save(os.path.join(\".\", \"filtered\", \"rsEEG_cleaned.fif\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /home/tomasgalle/UGent/thesis/tms-research/filtered/rsEEG_cleaned.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "rsEEG_copy.save(os.path.join(\".\", \"filtered\", \"rsEEG_cleaned.fif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated cleaning on all files in a directory\n",
    "Apply rsEEG or spTEP cleaning appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    raw = mne.io.read_raw_brainvision(file_path, preload=True)\n",
    "\n",
    "    # Apply correct pipeline\n",
    "    if \"rsEEG\" in file_path:\n",
    "        # Apply the rsEEG pipeline\n",
    "        print(f\"Processing rsEEG file: {file_path}\")\n",
    "    elif \"spTEP\" in file_path:\n",
    "        # Apply the spTEP pipeline\n",
    "        print(f\"Processing spTEP file: {file_path}\")\n",
    "\n",
    "DATASET_PATH = os.path.join(\".\", \"dataset\")\n",
    "\n",
    "files = [\n",
    "    os.path.join(DATASET_PATH, file)\n",
    "    for file in os.listdir(DATASET_PATH)\n",
    "    if file.endswith(\".vhdr\")\n",
    "]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(process_file, file) for file in files]\n",
    "    for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
